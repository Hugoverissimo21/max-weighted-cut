{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 12, 10,  0],\n",
       "       [12,  0,  0, 16],\n",
       "       [10,  0,  0,  0],\n",
       "       [ 0, 16,  0,  0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.adjacency_matrix(nx.read_graphml(\"graphs/04_500.graphml\")).todense()\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cut_weight(graph, S):\n",
    "    \"\"\"\n",
    "    complexidade k(n-k), k = len(subset)\n",
    "    W(n^2) e B(0)\n",
    "    O(n^2)\n",
    "\n",
    "    input: [[matriz adjacencia]], {subset1}, {subset2}\n",
    "    \"\"\"\n",
    "    total_weight = 0\n",
    "    for u in S:\n",
    "        for v in set(range(len(graph))) - S:\n",
    "            total_weight += graph[u][v]\n",
    "    \n",
    "    return total_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exhaustive search\n",
    "\n",
    "- ~~recurrence em q  - return max({A...}{...D} , {A...D}{...})~~\n",
    "\n",
    "- iterative - compare {A}{...} {AB}{...} ... {A...}{Z}\n",
    "\n",
    "penso q ambos seriam 2^n de complexidade pq arvore e n+n-1+n-2+... ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 3}, {1, 2}, np.int64(38))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def exhaustive_search(graph):\n",
    "    input_set = set(range(len(graph)))\n",
    "    subsets = []\n",
    "    n = len(input_set)\n",
    "    \n",
    "    # generate all subsets (complexy 2^V to generate * V to convert to set = O(V^2 * V))\n",
    "    for r in range(n + 1):\n",
    "        for subset in itertools.combinations(input_set, r):\n",
    "            subsets.append(set(subset))\n",
    "\n",
    "    best = input_set\n",
    "    weight = 0\n",
    "    for subset in subsets: # 2^n resultados para percorrer\n",
    "        new_weight = calculate_cut_weight(graph, subset) # k*(n-k) q é < 2^n , ent O(2^n * n^2)\n",
    "        if new_weight > weight:\n",
    "            best = subset\n",
    "            weight = new_weight\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return best, input_set-best, weight\n",
    "\n",
    "exhaustive_search(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# greedy heuristic\n",
    "\n",
    "pode ser sorted weights e maior é AB, ent S = {A} T = {B}, segudo maior CD, ent S={AC} T={BD}, algo desse genero\n",
    "\n",
    "mas se segundo maior é AC - S = {A} T = {BC} :: \n",
    "\n",
    "- if A and C in S or T: pass\n",
    "\n",
    "- if A in S or T: C to other\n",
    "\n",
    "- if neither in: randomly select - could compare to already in vertices but to complex?\n",
    "\n",
    "complexidade nlogn por causa do sort + n por iterar por cada um - logo complexidade final = nlogn ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset S: {1, 2}\n",
      "Subset T: {0, 3}\n",
      "Weight: 38\n"
     ]
    }
   ],
   "source": [
    "def max_weighted_cut_greedy(G):\n",
    "    num_vertices = len(G)\n",
    "    \n",
    "    # Step 1: Extract edges and their weights\n",
    "    edges = []\n",
    "    for i in range(num_vertices):\n",
    "        for j in range(i + 1, num_vertices):  # To avoid duplicate edges\n",
    "            weight = G[i, j]\n",
    "            edges.append((i, j, weight))\n",
    "\n",
    "    # Step 2: Sort edges in descending order based on their weights\n",
    "    edges.sort(key=lambda e: e[2], reverse=True)\n",
    "    \n",
    "    seen, S, T = set(), set(), set()\n",
    "\n",
    "    cut_weight = 0\n",
    "    # Step 3: Process each edge\n",
    "    for u, v, weight in edges:\n",
    "        if u not in seen and v not in seen: \n",
    "            # nenhum vertice visto\n",
    "            cut_weight += weight\n",
    "            seen.update({u,v})\n",
    "            S.add(u)\n",
    "            T.add(v)\n",
    "        elif u in S and v not in seen:\n",
    "            # u no primeiro set, v não visto\n",
    "            cut_weight += weight\n",
    "            seen.add(v)\n",
    "            T.add(v)\n",
    "        elif u in T and v not in seen:\n",
    "            # u no segundo set, v não visto\n",
    "            cut_weight += weight\n",
    "            seen.add(v)\n",
    "            S.add(v)\n",
    "        elif v in S and u not in seen:\n",
    "            # v no primeiro set, u não visto\n",
    "            cut_weight += weight\n",
    "            seen.add(u)\n",
    "            T.add(u)\n",
    "        elif v in T and u not in seen:\n",
    "            # v no segundo set, u não visto\n",
    "            cut_weight += weight\n",
    "            seen.add(u)\n",
    "            S.add(u)\n",
    "        elif v in T and u in S:\n",
    "            cut_weight += weight\n",
    "        elif v in S and u in T:\n",
    "            cut_weight += weight\n",
    "        else:\n",
    "            # v and u in the same set\n",
    "            pass\n",
    "\n",
    "    return S, T, cut_weight\n",
    "\n",
    "\n",
    "# Run the greedy heuristic\n",
    "S, T, weight = max_weighted_cut_greedy(G)\n",
    "\n",
    "print(\"Subset S:\", S)\n",
    "print(\"Subset T:\", T)\n",
    "print(\"Weight:\", weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: nan\n",
      "4: 1.0\n",
      "4: 1.0\n",
      "4: 1.0\n",
      "5: 1.0\n",
      "5: 1.0\n",
      "5: 0.65\n",
      "5: 1.0\n",
      "6: 1.0\n",
      "6: 1.0\n",
      "6: 1.0\n",
      "6: 0.99\n",
      "7: 1.0\n",
      "7: 1.0\n",
      "7: 1.0\n",
      "7: 1.0\n",
      "8: 1.0\n",
      "8: 1.0\n",
      "8: 1.0\n",
      "8: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/96b_h5gn3y33k0c7jsvrstmm0000gn/T/ipykernel_2366/1439463292.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(round(w1/w,2))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "graphs = sorted([f\"graphs/{x}\" for x in os.listdir(\"graphs\") if x[-7:] == \"graphml\"])[:20] # 188\n",
    "\n",
    "for G in graphs:\n",
    "    G = nx.adjacency_matrix(nx.read_graphml(G)).todense()\n",
    "    s,t, w = exhaustive_search(G)\n",
    "    s1,t1,w1 = max_weighted_cut_greedy(G)\n",
    "    print(len(G), end = \": \")\n",
    "    print(round(w1/w,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
